语言模型生成回答是在做一种“文字接龙”：未完成句子 --> 语言模型 --> 生成下一个token

下一个token = f(未完成句子) = ...a...b...c...d...   -->拥有数十亿个未知参数的函式 即模型：Transformer

通过把训练资料交给语言模型进行训练，可以将数十亿个参数找出来
(找参数的挑战：找到的参数可能只适用于特定资料，所以要换多组超参数来尝试)



第一阶段：Pre-train：

    在网络上找到大量文字资料拿来学习“文字接龙”（因为这一阶段人工介入很少，所以叫做Self-supervised Learning 自督导式学习） 

    理论上任何文字资料都可以拿来学“文字接龙”，但要排除不良内容/大量重复的内容的干扰

    经过第一阶段，语言模型已经学了很多东西，但回答的正确率不高，此时需要下一阶段由人类进行的帮助



第二阶段：Instruction Fine-tuning

    使用人力进行资料标注，给语言模型提供好的回答 （Supervised Learning 督导式学习）

    但如果只靠人力进行资料收集的话，受限于人力成本，效果并不好，所以，要将自督导式学习和督导式学习结合

    关键是以第一阶段的参数作为第二阶段的初始参数：
    先以网络上找到的大量文字资料生成初始参数，再通过instruction fine-tuning，以人类标注的少量资料对初始参数进行最佳化，
    产生不会和第一阶段初始参数差太多的参数



第三阶段：RLHF（Reinforcement Learning from Human Feedback）


